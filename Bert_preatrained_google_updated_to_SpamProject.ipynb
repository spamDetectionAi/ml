{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "109f804a-a701-419a-9bad-d2d26a9808c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import util as util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d445a0a6-bfb6-44cc-b7c2-198ef354093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spam_dataset_csv(csv_path):\n",
    "    \"\"\"Load the spam dataset from a TSV file\n",
    "\n",
    "    Args:\n",
    "         csv_path: Path to TSV file containing dataset.\n",
    "\n",
    "    Returns:\n",
    "        messages: A list of string values containing the text of each message.\n",
    "        labels: The binary labels (0 or 1) for each message. A 1 indicates spam.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    labels = []\n",
    "\n",
    "    with open(csv_path, 'r', newline='', encoding='utf8') as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for message, label in reader:\n",
    "            messages.append(message)\n",
    "            labels.append(1 if label == '1' else 0)\n",
    "\n",
    "    return messages, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f1bd532-c661-4a24-8fff-0fab5b30e18a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m train_messages, train_labels = util.load_spam_dataset(\u001b[33m'\u001b[39m\u001b[33mdata/train.tsv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m test_messages, test_labels = util.load_spam_dataset(\u001b[33m'\u001b[39m\u001b[33mdata/test.tsv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtest_messages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "train_messages, train_labels = util.load_spam_dataset('data/train.tsv')\n",
    "test_messages, test_labels = util.load_spam_dataset('data/test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a51699c-ab17-4a97-b9ac-c8135786e306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b774d1d3-d386-42e8-9d14-cfa06f97f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17332\\2621126986.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = tokenizer(train_messages, padding = True, truncation = True, return_tensors=\"pt\")\n",
    "\n",
    "print(tokenized_train.keys())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#move on device (GPU)\n",
    "tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d3227-53fb-4f20-8e13-3ca20a715631",
   "metadata": {},
   "source": [
    "Get CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad7f5c-f238-4536-8a2f-7e7498ab055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  hidden_train = model(**tokenized_train) #dim : [batch_size(nr_sentences), tokens, emb_dim]\n",
    "\n",
    "#get only the [CLS] hidden states\n",
    "cls_train = hidden_train.last_hidden_state[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4540b-5b53-4c2d-9a17-8091e81201f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
